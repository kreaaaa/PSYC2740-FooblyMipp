---
title: "FM-PreRegistration"
output:
  html_document:
    df_print: paged
---
# LOAD IN TIDYVERSE
```{r}
library(tidyverse)
```
# IMPORT DATA
```{r}
sona_data = read.csv("../data/savic-rhyming-sona.csv") %>%
  select(-sona_id) %>% mutate(data_source = "sona")


prolific_data = read.csv ("../data/savic-rhyming-prolific.csv") %>%
  select(-PROLIFIC_PID) %>% mutate(data_source = "prolific")

```
Making sure sona data and prolific data have the same amount of columns
```{r}
ncol(sona_data)
ncol(prolific_data)
prolific_data <- prolific_data %>% select(names(sona_data))
```

bind data from both sona and prolific 
```{r}
##prolific_data <- prolific_data %>% select(names(sona_data))
final_data = rbind(sona_data, prolific_data) %>%
 mutate(rt = as.numeric(rt),
        relatedness = as.factor(relatedness),
        condition = as.factor(condition))%>%
  mutate(condition = fct_recode(condition, 
                                "non-rhyming" = "1",
                               "rhyming" = "2")) %>%
  mutate(relatedness = fct_recode(relatedness,
                                  "related" = "unrelated",
                                  "unrelated" = "related")) %>%
 mutate(correct = tolower(correct))
```
# INSPECT DATA
 
```{r}
#number of rows and columns 
nrow(final_data)
ncol(final_data)

```
Number of columns = 49
Number of rows = 44306


## Unique subjects and trials 
```{r}
#unique participants and trials

final_data%>% 
group_by(ID)%>% 
count()
```
There are 197 unique subjects but only have complete data for  participants.
Subjects completed different numbers of 'trials' because of either slow responses to target trials or additional questions in demographics.

```{r}
final_data %>% 
  filter(typeoftrial == "sentence") %>%
  group_by(ID) %>% 
  count()
```
60 sentence trials were completed all participants except four:  232084287, 467885230, 727137633, 869755378.

```{r}
final_data %>% 
  filter(typeoftrial == "attention") %>%
  group_by(ID) %>% 
  count()
```
9 attention check trials were completed by all participants except the same four: 232084287, 467885230, 727137633, 869755378.

```{r}
final_data %>% 
  filter(typeoftrial == "target") %>%
  group_by(ID) %>% 
  count()
```
All participants completeted 55 trials; however, these 4 subject IDs did not appear in the data because they had no target data.

##  Columns and Levels of variables
```{r}
levels(final_data$condition)
levels(final_data$relatedness)
```
Our Condition and Relatedness columns indicate our independent variables.
Condition has 2 levels: non-rhyming and rhyming
Relatedness has 2 levels that we are evaluating (related and unrelated). In the data it has "novel" and "" too. No target trial has "". 

Our primary dependent variable columns are reaction time and correct for target trials. For our attention check and association task, we are looking at the response column. 

# BASIC DESCRIPTIVES
```{r}
demographics = final_data %>%
  filter(typeoftrial == "demographics") %>%
  select("ID","gender", "age", "education", "race", "hispanic", "dominant_hand", "alert_time", "english")%>%
  mutate(across(c("age","education"), ~ replace_na(., NA)))%>%
 mutate(across(c("gender","race","hispanic","dominant_hand","alert_time","english"),
                 ~ replace_na(., "NOT_FOUND"))) %>%
mutate(across(c("age","gender","education","race","hispanic", "dominant_hand", "alert_time", "english"),
              ~ifelse(. == "", "blank",.)))

subject_age= demographics%>%
  summarise(mean_age= mean(age, na.rm = TRUE),
            sd_age=sd(age, na.rm = TRUE))

gender_distribution= demographics%>%
  filter(gender != "blank") %>%
  count(gender)

race_distribution= demographics%>%
  filter(race != "blank")%>%
  count(race)

education_distribution= demographics%>%
  filter(education != "blank")%>%
  summarise(mean_education= mean(education, na.rm = TRUE),
            sd_education=sd(education, na.rm = TRUE))
```

Mean age is 33.63 years old with a standard deviation of 14.70. (M = 33.63, SD = 14.70)
Gender distribution: Women (n = 72), Men (n = 52), Nonbinary (n = 2)
Race distribution: Asian (n = 6), Black/African American (n = 24), Other (n = 6), White/Caucasian (n = 82), Multiracial (n = 8)
The mean education years is 14.65 with a standard deviation of 2.80 (M = 14.65, SD = 2.80). 


## Average accuracy in your experiment and the standard deviation of the accuracy?
```{r}
trial_data = final_data %>%
  filter(typeoftrial == "target") %>%
  select(type, correct, block_number, target, correct_key) %>%
  filter(block_number == 1) %>%
  mutate(correct = fct_recode(correct, 
                              "0" = "false",
                              "1" = "true")) %>%
  mutate(correct = as.numeric(as.character(correct)))

trial_accuracy = trial_data %>%
   summarise(mean_accuracy = mean(correct, na.rm = TRUE),
    sd_accuracy = sd(correct, na.rm = TRUE))

```
Average accuracy for target trials (not practice trials) with no exclusions (M = 0.87, SD = 0.34)

## Histogram of rt 
```{r}
basic_data = final_data %>% 
  filter(typeoftrial == "target") %>% 
  select(ID, rt, condition, relatedness, prime, response, type, correct, block_number, target, correct_key)

ggplot(basic_data, aes(x = rt)) + 
  geom_histogram(binwidth = 2, color = "firebrick2") +
  theme_minimal() +
  labs(title = "Histogram of Reaction Times", x = "Reaction Time (ms)", y = "Count")
    

geom_histogram(mapping = aes (x = as.numeric(rt)))             
```
Our histogram has concentrated reaction times under 2 seconds. From our data being displayed in this way, we can determine that we definitely will have outliers as some values are well over 1500 ms.

## Exclusions  
We excluded data from participants whose accuracy on attention check questions was less than 0.75. On the priming task, incorrect identification of the familiar noun or reaction times that are extremely short (less than 200 ms) or extremely long (greater than 1,500 ms) will result in removal of data. In addition, incomplete experiments will be removed from analyses. Finally, English fluency is necessary, so data will be removed if a participant’s first language is not English or they did not learn before the age of 4. 

```{r}

#editing all attention trials to adjust for typos
attention_trials= final_data%>% 
  filter(typeoftrial == "attention") %>% 
  select(ID, response, novel1, novel2, correct) %>% 
    rowwise() %>%
  mutate(response = ifelse(is.na(response), "blank", response)) %>%
  mutate(across(c(novel1, novel2), ~ replace_na(., "NOT_FOUND"))) %>% 
  mutate(edit_novel1 = adist(novel1, response),
         edit_novel2 = adist(novel2, response)) %>% 
  mutate(revised_correct = ifelse(edit_novel1 <= 2 |
                                    edit_novel2 <= 2,
                                    1, 0),
          mismatch = ifelse(correct == revised_correct, 0, 1)) %>%
  ungroup()

# mean accuracy for each participant
subject_attention_accuracy = attention_trials  %>% 
  group_by(ID)  %>% 
  summarise(mean_accuracy = mean(revised_correct))
print(subject_attention_accuracy)

# average reaction time for each subject in each condition in experiment
subject_reaction_time = priming_data %>%
  group_by(ID, condition) %>%
  summarise(mean_rt = mean(rt, na.rm = TRUE),
            sd_rt = sd(rt, na.rm = TRUE))  
print(subject_reaction_time)
# find IDs with less than 75% accuracy
low_acc_IDs = subject_attention_accuracy  %>% 
  filter(mean_accuracy < 0.75)  %>% 
  pull(ID)
```

### Target data after applying exclusions
```{r}

priming_data = final_data %>% 
  filter(typeoftrial == "target") %>% 
  select (ID, rt, condition, relatedness, prime, response, type, correct, block_number, target, correct_key) %>% 
  filter(!is.na(rt), rt> 200 , rt< 1500, correct == "true", block_number == 1) %>% 
  filter(relatedness %in% c("related", "unrelated")) %>%
  filter(!ID %in% low_acc_IDs)

priming_accuracy = priming_data %>% 
  mutate(acc = ifelse(correct == "true", 1,0)) %>%
  group_by(ID) %>%
  summarize(acc = mean(acc))

counts = final_data %>%
  group_by(condition, relatedness)%>%
  count()

```


```{r}
priming_data%>%
  group_by(condition, ID)%>%
  count()%>%
  group_by(condition)%>%
  count() 
```
- how many participants were recruited = 225
- how many did not finish the game = 28
- how many were excluded based on ALL pre-registered criteria = 60

## Bar plot
```{r}
# Summarise the data and directly use it in the plotting step
mean_scores = priming_data %>%
  group_by(condition, relatedness) %>%
  summarise(mean_rt = mean(rt, na.rm = TRUE),
          sd_rt = sd(rt, na.rm = TRUE)) %>%
  left_join(counts)%>%
  mutate(SE = sd_rt/sqrt(n),
         ymin = mean_rt - 1.96*SE,
          ymax = mean_rt + 1.96*SE) 

mean_scores %>%
  ggplot(mapping = aes(x = condition, y = mean_rt, group = relatedness, fill = relatedness)) +
  geom_col(position = "dodge") +
  geom_errorbar(
    aes(ymin = ymin, ymax = ymax),
    width = 0.25,
    position = position_dodge(width = .85)) +
  theme_minimal() +
  ylim(0, 900)+
  scale_fill_manual(values = c("firebrick2", "lightblue")) +
  labs(
    title = "Mean Reaction Time by Condition and Relatedness",
    x = "Condition",
    y = "Mean Reaction Time"
  ) +
  guides(fill = guide_legend(title = "Relatedness"))
```

By only analyzing our plot, we notice that the non-rhyming x unrelated condition has a faster mean reaction time compared to the rhyming x unrelated condition. In the related condition, the rhyming condition has a faster mean reaction time than the non-rhyming condition.
Error bars denote 95% confidence interval.

# INFERENTIAL STATISTICS

Inspecting the model
## Priming model (rt_model)
```{r}
#install.packages("lmerTest")
library(lmerTest)
library(performance)

rt_model = lmer(data = priming_data, rt~ relatedness*condition + (1|ID))
```

```{r}
car::Anova(rt_model)
nobs(rt_model) 
print(nobs(rt_model))
check_model(rt_model)
```

```{r}
emmeans :: emmeans(rt_model, 
                   pairwise ~ relatedness | condition, 
                   adjust = "tukey")
```



Our primary research question is whether exposure to language containing rhyming words can help to foster semantic links between novel and familiar words. If rhyming facilitates semantic integration, participants should identify familiar nouns faster when the prime is related to and rhymes with the familiar noun.

The model revealed a significant main effect of relatedness (χ² (1, N = 3796)= 37.16, p < 0.001), suggesting that relatedness significantly influenced reaction times. The effect of condition was not significant (χ² = (1, N = 3796) = 3.11, p = 0.078),suggesting a potential influence of condition. The significant interaction between relatedness and condition (χ² = (1, N = 3796) = 13.18, p < 0.001) suggests that the effect of relatedness on reaction time is moderated by the condition.







