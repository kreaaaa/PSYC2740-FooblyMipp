2+3
log(1)
?sum
args(factorial)
args(round)
round(15.789)
mystring= 'i love pancake'
mystring
x= sum(1,2,3)
x
r=rnorm (50, mean=20, sd=1)
hist(r)
r=rnorm (1000, mean=20, sd=1)
hist(r)
vec= c(51:55)
vec
vec[4]
v=c("ABC", 34)
v
myclass= list(names=c("Natalie", "Katie", "Lily", "Mitri"), ages c(21,21,20,22))
myclass= list(names=c("Natalie", "Katie", "Lily", "Mitri"), ages=c(21,21,20,22))
myclass
mean(myclass$ages)
x=myclass$ages
mean(x)
View(iris)
hist(iris$Sepal.Length)
#install.packages("lmerTest")
library(lmerTest)
rt_model = lmer(data = priming_data, rt~ relatedness*condition + (1|ID))
library(tidyverse)
sona_data = read.csv("../data/savic-rhyming-sona.csv") %>%
select(-sona_id) %>% mutate(data_source = "sona")
prolific_data = read.csv ("../data/savic-rhyming-prolific.csv") %>%
select(-PROLIFIC_PID) %>% mutate(data_source = "prolific")
ncol(sona_data)
ncol(prolific_data)
prolific_data <- prolific_data %>% select(names(sona_data))
##prolific_data <- prolific_data %>% select(names(sona_data))
final_data = rbind(sona_data, prolific_data) %>%
mutate(rt = as.numeric(rt),
relatedness = as.factor(relatedness),
condition = as.factor(condition))%>%
mutate(condition = fct_recode(condition,
"non-rhyming" = "1",
"rhyming" = "2")) %>%
mutate(relatedness = fct_recode(relatedness,
"related" = "unrelated",
"unrelated" = "related")) %>%
mutate(correct = tolower(correct))
#number of rows and columns
nrow(final_data)
ncol(final_data)
#unique participants and trials
final_data%>%
group_by(ID)%>%
count()
final_data %>%
filter(typeoftrial == "sentence") %>%
group_by(ID) %>%
count()
final_data %>%
filter(typeoftrial == "attention") %>%
group_by(ID) %>%
count()
final_data %>%
filter(typeoftrial == "target") %>%
group_by(ID) %>%
count()
levels(final_data$condition)
levels(final_data$relatedness)
demographics = final_data %>%
filter(typeoftrial == "demographics") %>%
select("ID","gender", "age", "education", "race", "hispanic", "dominant_hand", "alert_time", "english")%>%
mutate(across(c("age","education"), ~ replace_na(., NA)))%>%
mutate(across(c("gender","race","hispanic","dominant_hand","alert_time","english"),
~ replace_na(., "NOT_FOUND"))) %>%
mutate(across(c("age","gender","education","race","hispanic", "dominant_hand", "alert_time", "english"),
~ifelse(. == "", "blank",.)))
subject_age= demographics%>%
summarise(mean_age= mean(age, na.rm = TRUE),
sd_age=sd(age, na.rm = TRUE))
gender_distribution= demographics%>%
filter(gender != "blank") %>%
count(gender)
race_distribution= demographics%>%
filter(race != "blank")%>%
count(race)
education_distribution= demographics%>%
filter(education != "blank")%>%
count(education)
trial_data = final_data %>%
filter(typeoftrial == "target") %>%
select(type, correct, block_number, target, correct_key) %>%
filter(block_number == 1) %>%
mutate(correct = fct_recode(correct,
"0" = "false",
"1" = "true")) %>%
mutate(correct = as.numeric(as.character(correct)))
trial_accuracy = trial_data %>%
summarise(mean_accuracy = mean(correct, na.rm = TRUE),
sd_accuracy = sd(correct, na.rm = TRUE))
basic_data = final_data %>%
filter(typeoftrial == "target") %>%
select(ID, rt, condition, relatedness, prime, response, type, correct, block_number, target, correct_key)
ggplot(basic_data, aes(x = rt)) +
geom_histogram(binwidth = 1, color = "firebrick2") +
theme_minimal() +
labs(title = "Histogram of Reaction Times", x = "Reaction Time (ms)", y = "Count")
geom_histogram(mapping = aes (x = as.numeric(rt)))
#editing all attention trials to adjust for typos
attention_trials= final_data%>%
filter(typeoftrial == "attention") %>%
select(ID, response, novel1, novel2, correct) %>%
rowwise() %>%
mutate(response = ifelse(is.na(response), "blank", response)) %>%
mutate(across(c(novel1, novel2), ~ replace_na(., "NOT_FOUND"))) %>%
mutate(edit_novel1 = adist(novel1, response),
edit_novel2 = adist(novel2, response)) %>%
mutate(revised_correct = ifelse(edit_novel1 <= 2 |
edit_novel2 <= 2,
1, 0),
mismatch = ifelse(correct == revised_correct, 0, 1)) %>%
ungroup()
## summarize participant accuracy on attention trials
subject_attention_accuracy = attention_trials  %>%
group_by(ID)  %>%
summarise(mean_accuracy = mean(revised_correct))
# find IDs with less than 75% accuracy
low_acc_IDs = subject_attention_accuracy  %>%
filter(mean_accuracy < 0.75)  %>%
pull(ID)
#target data after applying exclusions
priming_data = final_data %>% filter(typeoftrial == "target") %>%
select (ID, rt, condition, relatedness, prime, response, type, correct, block_number, target, correct_key) %>%
filter(!is.na(rt), rt> 200 , rt< 1500, correct == "true", block_number == 1) %>%
filter(relatedness %in% c("related", "unrelated")) %>%
filter(!ID %in% low_acc_IDs)
priming_accuracy = priming_data %>%
mutate(acc = ifelse(correct == "true", 1,0)) %>%
group_by(ID) %>%
summarize(acc = mean(acc))
priming_data%>%
group_by(condition, ID)%>%
count()%>%
group_by(condition)%>%
count()
priming_data %>%
group_by(condition, relatedness) %>%
summarise(mean_rt = mean(rt)) %>%
ggplot() +
geom_col(mapping= aes(x= condition, y= mean_rt,
group= relatedness, fill= relatedness),
position = "dodge") +
theme_minimal() +
scale_fill_manual(values = c("firebrick2", "lightblue"))+
labs(title = "Mean Reaction Time by Condition and Relatedness",
x = "Condition",
y = "Mean Reaction Time") +
guides(fill = guide_legend(title = "Relatedness"))
#install.packages("lmerTest")
library(lmerTest)
rt_model = lmer(data = priming_data, rt~ relatedness*condition + (1|ID))
car::Anova(rt_model)
nobs(rt_model)
print(nobs(rt_model))
check_model(rt_model)
car::Anova(rt_model)
nobs(rt_model)
print(nobs(rt_model))
check_model(rt_model)
#install.packages("lmerTest")
library(lmerTest)
library(performance)
rt_model = lmer(data = priming_data, rt~ relatedness*condition + (1|ID))
car::Anova(rt_model)
nobs(rt_model)
print(nobs(rt_model))
check_model(rt_model)
library(tidyverse)
library(tidyverse)
sona_data = read.csv("../data/savic-rhyming-sona.csv") %>%
select(-sona_id) %>% mutate(data_source = "sona")
prolific_data = read.csv ("../data/savic-rhyming-prolific.csv") %>%
select(-PROLIFIC_PID) %>% mutate(data_source = "prolific")
ncol(sona_data)
ncol(prolific_data)
prolific_data <- prolific_data %>% select(names(sona_data))
##prolific_data <- prolific_data %>% select(names(sona_data))
final_data = rbind(sona_data, prolific_data) %>%
mutate(rt = as.numeric(rt),
relatedness = as.factor(relatedness),
condition = as.factor(condition))%>%
mutate(condition = fct_recode(condition,
"non-rhyming" = "1",
"rhyming" = "2")) %>%
mutate(relatedness = fct_recode(relatedness,
"related" = "unrelated",
"unrelated" = "related")) %>%
mutate(correct = tolower(correct))
#number of rows and columns
nrow(final_data)
ncol(final_data)
#unique participants and trials
final_data%>%
group_by(ID)%>%
count()
final_data %>%
filter(typeoftrial == "sentence") %>%
group_by(ID) %>%
count()
final_data %>%
filter(typeoftrial == "attention") %>%
group_by(ID) %>%
count()
final_data %>%
filter(typeoftrial == "target") %>%
group_by(ID) %>%
count()
levels(final_data$condition)
levels(final_data$relatedness)
demographics = final_data %>%
filter(typeoftrial == "demographics") %>%
select("ID","gender", "age", "education", "race", "hispanic", "dominant_hand", "alert_time", "english")%>%
mutate(across(c("age","education"), ~ replace_na(., NA)))%>%
mutate(across(c("gender","race","hispanic","dominant_hand","alert_time","english"),
~ replace_na(., "NOT_FOUND"))) %>%
mutate(across(c("age","gender","education","race","hispanic", "dominant_hand", "alert_time", "english"),
~ifelse(. == "", "blank",.)))
subject_age= demographics%>%
summarise(mean_age= mean(age, na.rm = TRUE),
sd_age=sd(age, na.rm = TRUE))
gender_distribution= demographics%>%
filter(gender != "blank") %>%
count(gender)
race_distribution= demographics%>%
filter(race != "blank")%>%
count(race)
education_distribution= demographics%>%
filter(education != "blank")%>%
count(education)
trial_data = final_data %>%
filter(typeoftrial == "target") %>%
select(type, correct, block_number, target, correct_key) %>%
filter(block_number == 1) %>%
mutate(correct = fct_recode(correct,
"0" = "false",
"1" = "true")) %>%
mutate(correct = as.numeric(as.character(correct)))
trial_accuracy = trial_data %>%
summarise(mean_accuracy = mean(correct, na.rm = TRUE),
sd_accuracy = sd(correct, na.rm = TRUE))
basic_data = final_data %>%
filter(typeoftrial == "target") %>%
select(ID, rt, condition, relatedness, prime, response, type, correct, block_number, target, correct_key)
ggplot(basic_data, aes(x = rt)) +
geom_histogram(binwidth = 1, color = "firebrick2") +
theme_minimal() +
labs(title = "Histogram of Reaction Times", x = "Reaction Time (ms)", y = "Count")
geom_histogram(mapping = aes (x = as.numeric(rt)))
#editing all attention trials to adjust for typos
attention_trials= final_data%>%
filter(typeoftrial == "attention") %>%
select(ID, response, novel1, novel2, correct) %>%
rowwise() %>%
mutate(response = ifelse(is.na(response), "blank", response)) %>%
mutate(across(c(novel1, novel2), ~ replace_na(., "NOT_FOUND"))) %>%
mutate(edit_novel1 = adist(novel1, response),
edit_novel2 = adist(novel2, response)) %>%
mutate(revised_correct = ifelse(edit_novel1 <= 2 |
edit_novel2 <= 2,
1, 0),
mismatch = ifelse(correct == revised_correct, 0, 1)) %>%
ungroup()
## summarize participant accuracy on attention trials
subject_attention_accuracy = attention_trials  %>%
group_by(ID)  %>%
summarise(mean_accuracy = mean(revised_correct))
# find IDs with less than 75% accuracy
low_acc_IDs = subject_attention_accuracy  %>%
filter(mean_accuracy < 0.75)  %>%
pull(ID)
#target data after applying exclusions
priming_data = final_data %>% filter(typeoftrial == "target") %>%
select (ID, rt, condition, relatedness, prime, response, type, correct, block_number, target, correct_key) %>%
filter(!is.na(rt), rt> 200 , rt< 1500, correct == "true", block_number == 1) %>%
filter(relatedness %in% c("related", "unrelated")) %>%
filter(!ID %in% low_acc_IDs)
priming_accuracy = priming_data %>%
mutate(acc = ifelse(correct == "true", 1,0)) %>%
group_by(ID) %>%
summarize(acc = mean(acc))
priming_data%>%
group_by(condition, ID)%>%
count()%>%
group_by(condition)%>%
count()
priming_data%>%
group_by(condition, ID)%>%
count()%>%
group_by(condition)%>%
count()
priming_data %>%
group_by(condition, relatedness) %>%
summarise(mean_rt = mean(rt)) %>%
ggplot() +
geom_col(mapping= aes(x= condition, y= mean_rt,
group= relatedness, fill= relatedness),
position = "dodge") +
theme_minimal() +
scale_fill_manual(values = c("firebrick2", "lightblue"))+
labs(title = "Mean Reaction Time by Condition and Relatedness",
x = "Condition",
y = "Mean Reaction Time") +
guides(fill = guide_legend(title = "Relatedness"))
#install.packages("lmerTest")
library(lmerTest)
library(performance)
rt_model = lmer(data = priming_data, rt~ relatedness*condition + (1|ID))
car::Anova(rt_model)
nobs(rt_model)
print(nobs(rt_model))
check_model(rt_model)
#install.packages("lmerTest")
library(lmerTest)
library(performance)
library(pathwork)
priming_data%>%
group_by(condition, ID)%>%
count()%>%
group_by(condition)%>%
count() %>%
#install.packages("lmerTest")
library(lmerTest)
library(performance)
rt_model = lmer(data = priming_data, rt~ relatedness*condition + (1|ID))
car::Anova(rt_model)
nobs(rt_model)
print(nobs(rt_model))
check_model(rt_model)
demographics = final_data %>%
filter(typeoftrial == "demographics") %>%
select("ID","gender", "age", "education", "race", "hispanic", "dominant_hand", "alert_time", "english")%>%
mutate(across(c("age","education"), ~ replace_na(., NA)))%>%
mutate(across(c("gender","race","hispanic","dominant_hand","alert_time","english"),
~ replace_na(., "NOT_FOUND"))) %>%
mutate(across(c("age","gender","education","race","hispanic", "dominant_hand", "alert_time", "english"),
~ifelse(. == "", "blank",.)))
subject_age= demographics%>%
summarise(mean_age= mean(age, na.rm = TRUE),
sd_age=sd(age, na.rm = TRUE))
gender_distribution= demographics%>%
filter(gender != "blank") %>%
count(gender)
race_distribution= demographics%>%
filter(race != "blank")%>%
count(race)
education_distribution= demographics%>%
filter(education != "blank")%>%
count(education)
demographics = final_data %>%
filter(typeoftrial == "demographics") %>%
select("ID","gender", "age", "education", "race", "hispanic", "dominant_hand", "alert_time", "english")%>%
mutate(across(c("age","education"), ~ replace_na(., NA)))%>%
mutate(across(c("gender","race","hispanic","dominant_hand","alert_time","english"),
~ replace_na(., "NOT_FOUND"))) %>%
mutate(across(c("age","gender","education","race","hispanic", "dominant_hand", "alert_time", "english"),
~ifelse(. == "", "blank",.)))
print (subject_age= demographics%>%
summarise(mean_age= mean(age, na.rm = TRUE),
sd_age=sd(age, na.rm = TRUE)))
subject_age= demographics%>%
summarise(mean_age= mean(age, na.rm = TRUE),
sd_age=sd(age, na.rm = TRUE))
gender_distribution= demographics%>%
filter(gender != "blank") %>%
count(gender)
race_distribution= demographics%>%
filter(race != "blank")%>%
count(race)
education_distribution= demographics%>%
filter(education != "blank")%>%
count(education)
subject_age= demographics%>%
summarise(mean_age= mean(age, na.rm = TRUE),
sd_age=sd(age, na.rm = TRUE))
print(subject_age)
gender_distribution= demographics%>%
filter(gender != "blank") %>%
count(gender)
print(gender_distribution)
race_distribution= demographics%>%
filter(race != "blank")%>%
count(race)
print(race_distribution)
education_distribution= demographics%>%
filter(education != "blank")%>%
count(education)
print(education_distribution)
#install.packages("lmerTest")
library(lmerTest)
library(performance)
rt_model = lmer(data = priming_data, rt~ relatedness*condition + (1|ID))
car::Anova(rt_model)
nobs(rt_model)
print(nobs(rt_model))
check_model(rt_model)
