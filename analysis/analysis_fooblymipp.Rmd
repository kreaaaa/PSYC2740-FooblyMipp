---
title: "FM-PreRegistration"
output:
  html_document:
    df_print: paged
---
```{r}
library(tidyverse)
```

# IMPORT DATA
```{r}
sona_data = read.csv("../data/savic-rhyming-sona.csv") %>%
  select(-sona_id) %>% mutate(data_source = "sona")


prolific_data = read.csv ("../data/savic-rhyming-prolific.csv") %>%
  select(-PROLIFIC_PID) %>% mutate(data_source = "prolific")


```

Making sure sona data and prolific data have the same amount of columns for binding. 
```{r}
ncol(sona_data)
ncol(prolific_data)
prolific_data <- prolific_data %>% select(names(sona_data))
```

Bind data from both sona and prolific 
```{r}
##prolific_data <- prolific_data %>% select(names(sona_data))
final_data = rbind(sona_data, prolific_data) %>%
 mutate(rt = as.numeric(rt),
        relatedness = as.factor(relatedness),
        condition = as.factor(condition))%>%
  mutate(condition = fct_recode(condition, 
                                "non-rhyming" = "1",
                               "rhyming" = "2")) %>%
  mutate(relatedness = fct_recode(relatedness,
                                  "related" = "unrelated",
                                  "unrelated" = "related")) %>%
 mutate(correct = tolower(correct))
```

## Participant Exclusions based on incomplete experiments.

```{r}
final_data%>% 
group_by(ID)%>% 
count()
```

There are 217 unique subjects.
Subjects completed different numbers of 'trials' because of either slow responses to target trials or additional questions in demographics.

```{r}
final_data %>% 
  filter(typeoftrial == "sentence") %>%
  group_by(ID) %>% 
  count()

final_data %>% 
  filter(typeoftrial == "attention") %>%
  group_by(ID) %>% 
  count()

```
212 participants completed the Training phase, given by 60 sentence trials and 9 attention check trials.

```{r}
final_data %>% 
  filter(typeoftrial == "target") %>%
  group_by(ID) %>% 
  count()
```
211 participants completeted 55 trials (the full amount of target trials). At this point, 27 participants have been excluded.

## Verification of Recorded Data

```{r}
levels(final_data$condition)
levels(final_data$relatedness)
```

Our Condition and Relatedness columns indicate our independent variables.
Condition has 2 levels: non-rhyming and rhyming
Relatedness has 2 levels that we are evaluating (related and unrelated). 
In the data it has "novel" and "" too. No target trial has "". 

Our primary dependent variable columns are 'reaction time' and 'correct' for target trials. For our attention check and association task, we are looking at the response column. 

## Demographic Data: Basic Descriptives

```{r}
demographics = final_data %>%
  filter(typeoftrial == "demographics") %>%
  select("ID","gender", "age", "education", "race", "hispanic", "dominant_hand", "alert_time", "english")%>%
  mutate(across(c("age","education"), ~ replace_na(., NA)))%>%
 mutate(across(c("gender","race","hispanic","dominant_hand","alert_time","english"),
                 ~ replace_na(., "NOT_FOUND"))) %>%
mutate(across(c("age","gender","education","race","hispanic", "dominant_hand", "alert_time", "english"),
              ~ifelse(. == "", "blank",.)))

subject_age= demographics%>%
  summarise(mean_age= mean(age, na.rm = TRUE),
            sd_age=sd(age, na.rm = TRUE))

gender_distribution= demographics%>%
  filter(gender != "blank") %>%
  count(gender)

race_distribution= demographics%>%
  filter(race != "blank")%>%
  count(race)

education_distribution= demographics%>%
  filter(education != "blank")%>%
  count(education)

mean_education= demographics%>%
  summarise(mean_education= mean(education, na.rm = TRUE),
            sd_education=sd(education, na.rm = TRUE))
```

For demographics ( N = 211 )
Mean age (M = 33.91, SD = 15.41)
Gender distribution: 
  Women (N = 116) - 55.00% 
  Men (N = 93) - 44.08 %
  Nonbinary (N = 2) - 1.00 %
Race distribution: 
  Asian (N = 11) - 5.21%
  Black/African American (N = 36) - 17.06%
  Other (N = 10)
  White/Caucasian (N = 141) - 66.82%
  Multiracial (N = 13) - 6.16%
Mean education (M = 14.50, SD = 2.77). 


## Average accuracy in your experiment and the standard deviation of the accuracy.
This histogram has been excluded from the results; however, we decided that this supplementary information will be kept in the code. 

Average accuracy for target trials (not practice trials) before exclusions based on pre-registered threshold
(M = 0.87, SD = 0.34)

```{r}
trial_data = final_data %>%
  filter(typeoftrial == "target") %>%
  select(type, correct, block_number, target, correct_key) %>%
  filter(block_number == 1) %>%
  mutate(correct = fct_recode(correct, 
                              "0" = "false",
                              "1" = "true")) %>%
  mutate(correct = as.numeric(as.character(correct)))

trial_accuracy = trial_data %>%
   summarise(mean_accuracy = mean(correct, na.rm = TRUE),
    sd_accuracy = sd(correct, na.rm = TRUE))

```

```{r}
basic_data = final_data %>% 
  filter(typeoftrial == "target") %>% 
  select(ID, rt, condition, relatedness, prime, response, type, correct, block_number, target, correct_key)

ggplot(basic_data, aes(x = rt)) + 
  geom_histogram(binwidth = 2, color = "firebrick2") +
  theme_minimal() +
  labs(title = "Histogram of Reaction Times", x = "Reaction Time (ms)", y = "Count")
    

geom_histogram(mapping = aes (x = as.numeric(rt)))             
```
Our histogram has concentrated reaction times under 2 seconds. From our data being displayed in this way, we can determine that we definitely will have outliers as some values are well over 1

## Exclusions  
We excluded data from participants whose accuracy on attention check questions was less than 0.75. On the priming task, incorrect identification of the familiar noun or reaction times that are extremely short (less than 200 ms) or extremely long (greater than 1,500 ms) will result in removal of data. In addition, incomplete experiments will be removed from analyses. Finally, English fluency is necessary, so data will be removed if a participantâ€™s first language is not English or they did not learn before the age of 4. 

The data collected for the attention check questions was adjusted to account for typos of 1-2 letters.
There were 65 participants excluded due to not reaching the mandatory threshold of 75% accuracy on attention checks.
```{r}
#editing all attention trials to adjust for typos

attention_trials= final_data%>% 
  filter(typeoftrial == "attention") %>% 
  select(ID, response, novel1, novel2, correct) %>% 
    rowwise() %>%
  mutate(response = ifelse(is.na(response), "blank", response)) %>%
  mutate(across(c(novel1, novel2), ~ replace_na(., "NOT_FOUND"))) %>% 
  mutate(edit_novel1 = adist(novel1, response),
         edit_novel2 = adist(novel2, response)) %>% 
  mutate(revised_correct = ifelse(edit_novel1 <= 2 |
                                    edit_novel2 <= 2,
                                    1, 0),
          mismatch = ifelse(correct == revised_correct, 0, 1)) %>%
  ungroup()

# mean accuracy for each participant
subject_attention_accuracy = attention_trials  %>% 
  group_by(ID)  %>% 
  summarise(mean_accuracy = mean(revised_correct))
print(subject_attention_accuracy)

# find IDs with less than 75% accuracy
low_acc_IDs = subject_attention_accuracy  %>% 
  filter(mean_accuracy < 0.75)  %>% 
  pull(ID)
```

### Target data after applying exclusions
```{r}
priming_data = final_data %>% 
  filter(typeoftrial == "target") %>% 
  select (ID, rt, condition, relatedness, prime, response, type, correct, block_number, target, correct_key) %>% 
  filter(!is.na(rt), rt> 200 , rt< 1500, correct == "true", block_number == 1) %>% 
  filter(relatedness %in% c("related", "unrelated")) %>%
  filter(!ID %in% low_acc_IDs)

# average reaction time for each subject in each condition in experiment
subject_reaction_time = priming_data %>%
  group_by(ID, condition) %>%
  summarise(mean_rt = mean(rt, na.rm = TRUE),
            sd_rt = sd(rt, na.rm = TRUE))  

priming_accuracy = priming_data %>% 
  mutate(acc = ifelse(correct == "true", 1,0)) %>%
  group_by(ID) %>%
  summarize(acc = mean(acc))

counts = final_data %>%
  group_by(condition, relatedness)%>%
  count()

```


```{r}
priming_data%>%
  group_by(condition, ID)%>%
  count()%>%
  group_by(condition)%>%
  count() 
```
- how many participants were recruited: 238
- how many did not finish the game: 27
- how many were excluded based on ALL pre-registered criteria: 92
- after exclusions, 
    non-rhyming: 74
    rhyming: 72
  
## Bar plot: Mean Reaction Time by Condition and Relatedness
```{r}
mean_scores = priming_data %>%
  group_by(condition, relatedness) %>%
  summarise(mean_rt = mean(rt, na.rm = TRUE),
          sd_rt = sd(rt, na.rm = TRUE)) %>%
  left_join(counts)%>%
  mutate(SE = sd_rt/sqrt(n),
         ymin = mean_rt - 1.96*SE,
          ymax = mean_rt + 1.96*SE) 

mean_scores %>%
  ggplot(mapping = aes(x = condition, y = mean_rt, group = relatedness, fill = relatedness)) +
  geom_col(position = "dodge") +
  geom_errorbar(
    aes(ymin = ymin, ymax = ymax),
    width = 0.25,
    position = position_dodge(width = .85)) +
  theme_minimal() +
  ylim(0, 900)+
  scale_fill_manual(values = c("firebrick2", "lightblue")) +
  labs(
    title = "Mean Reaction Time by Condition and Relatedness",
    x = "Condition",
    y = "Mean Reaction Time"
  ) +
  guides(fill = guide_legend(title = "Relatedness"))
```

By only analyzing our plot, we notice that the Non-rhyming x Unrelated condition has a faster mean reaction time compared to the Rhyming x Unrelated condition. In the Related condition, the rhyming condition has a faster mean reaction time than the non-rhyming condition.
Error bars denote 95% confidence interval.

## INFERENTIAL STATISTICS

Priming model (rt_model)
```{r}
#install.packages("lmerTest")
library(lmerTest)
library(performance)

rt_model = lmer(data = priming_data, rt~ relatedness*condition + (1|ID))


```
`

```{r}
car::Anova(rt_model)
nobs(rt_model) 
print(nobs(rt_model))
check_model(rt_model)
```

```{r}
emmeans :: emmeans(rt_model, 
                   pairwise ~ relatedness | condition, 
                   adjust = "tukey")
```



Our primary research question is whether exposure to language containing rhyming words can help to foster semantic links between novel and familiar words. If rhyming facilitates semantic integration, participants should identify familiar nouns faster when the prime is related to and rhymes with the familiar noun.

The model revealed a significant main effect of relatedness (Ï‡Â² (1, N = 4037)= 44.61, p < 0.001), suggesting that relatedness significantly influenced reaction times. The effect of condition was not significant (Ï‡Â² = (1, N = 4037) = 2.38, p = 0.12),suggesting a potential influence of condition. The significant interaction between relatednesss and condition (Ï‡Â² = (1, N = 4037) = 17.31, p < 0.001) suggests that the effect of relatedness on reaction time is moderated by the condition.

The pairwise comparison 






